\documentclass[pageno]{jpaper}

%replace XXX with the submission number you are given from the ISCA submission site.
\newcommand{\IWreport}{2012}
\newcommand{\step}{\longrightarrow}
\newcommand{\bstep}{\Downarrow}

\usepackage[normalem]{ulem}
\usepackage{amsfonts}
\usepackage{amssymb,amsmath}
\usepackage{bussproofs}
\usepackage{syntax}
\usepackage{textgreek}
\usepackage{listings}
\usepackage{color}

\begin{document}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\ttfamily,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
%  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Caml,                  % the language of the code
  otherkeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{gray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\title{An ML-like programming language with typeclasses}

\date{}
\maketitle

\thispagestyle{empty}

\begin{abstract}

\end{abstract}

\section{Introduction}

\section{Notation}

\subsection{Inference rules}
Throughout this paper, I'll be using a simple notation for expressing relations and their inference rules.
Suppose we wanted to define the less-than-or-equal-to ($\leq$) relation on $\mathbb{N}$.
This relation is infinite,
so we can't describe it just by listing all the pairs of numbers that satisfy it.
We instead describe the relation with a list of axioms and inference rules. So, we can say that
forall $n$, $n \leq n$; and we can say that if $n \leq m$ then $n \leq m+1$. These two rules fully express the $\leq$ relation.
The Gentzen notation for these rules is:

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$n \leq n$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$n \leq m$}
\UnaryInfC{$n \leq m+1$}
\end{prooftree}

So to write down an inference rule, we put our assumptions above the line (and there may be more than one,
separated by spaces), and our conclusion (usually just one) below the line.

\subsection{Grammars}
The syntax of a programming language can be described by its grammar, which is basically a set of rules
for producing valid expressions in the language. We can express a language's grammar in BNF notation.
For example, a (rough) grammar for a language of arithmetic expressions

\begin{grammar}

<e> ::= <e> + <e>
\alt <e> * <e>
\alt <e> - <e>
\alt <e>

<nat> ::=
0
\alt succ <nat>

\end{grammar}

Sometimes I will use this notation to specify actual language syntax, other times I will use it
to describe a data structure more roughly.

\section{Base Language}
While the Turing machine is the model of computation that gets the most press,
and intuitively corresponds to the low-level behavior of computers, it is really messy,
and hence difficult to reason about. It is not really suitable as a model of the
semantics of high level programming languages.

The most natural and elegant way to model high level programming languages is
with various kinds of of lambda calculi, which are a collection of logical systems
for expressing and reasoning about functions.  My programming language is one
such system, albeit embellished with several features.

I'll start by discussing the simplest lambda calculus---the untyped one---on
which all other versions are built.
\subsection{Untyped Lambda Calculus}

The basis of all varieties of the lambda calculus is just two operations: \textbf{function abstraction},
and \textbf{function application}.
In the untyped version, this is \textit{all} we have.
We assume that we have an infinite set of variables.
Then the syntax is
\begin{grammar}

<exp> ::= <variable>
\alt $\lambda$ <variable> . <exp>
\alt <exp> <exp>

\end{grammar}

In OCaml, this is represented by the type
\begin{lstlisting}

type variable = string
type exp = 
   | Var of variable
   | Lambda of variable * exp
   | App of exp * exp

\end{lstlisting}

The $\lambda$ expression represents function abstraction. The abstraction $\lambda x.t$ denotes
a function taking an argument $x$ and returning $t$. The term consisting of two adjacent sub-terms $t_1 t_2$ represents the application of $t_1$ to $t_2$.

Since these terms represent computer programs that are actually supposed to \textit{do} something, we want to
define a relation that says what a given expression evaluates to.

The real work of evaluation happens in function application. What does $(\lambda x.t_1)t_2$ evaluate to?
It seems clear that we want to replace occurrences $x$ in $t_1$ with $t_2$.
For we want these $\lambda$ terms to behave like ordinary functions, and this is how ordinary functions work.
For instance, if $f(x) = x + 1$, $f(13) = 13 + 1 = 14$, where we've applied $f$ to $13$ by substituting
$13$ for all the instances of $x$ in the definition of $f$.

But substituting for \textit{all} the occurrences of the variable turns out to be too much.
For instance, in the function application $(\lambda x. x (\lambda x. x y)) z$, we don't want to replace the inner
$x$ because it is bound in a different $\lambda$ than the one being applied.
So we want this expression to evaluate to $z (\lambda x. x y)$. The crucial distinction here is between
free and bound variables. Essentially, an occurrence of a variable $x$ is bound if there is an enclosing $\lambda$ abstraction taking $x$ as an argument.  It's free otherwise. So in the expression $\lambda x. x y$,
$x$ is bound and $y$ is free.  So, the proper way to substitute a term for a variable is to replace only
the free occurrences of the variable. 

There is one more kink we need to iron out in the definition of substitution. Consider the expression
$e = (\lambda x. \lambda y. x y) y$. If we substitute for all the free occurrences of $x$ as described, we get
$\lambda y.y y$. But now consider $e' = (\lambda x. \lambda z. x z) y$. I've only renamed $y$ to $z$, so
$e$ is in some sense equivalent to $e'$. But substituting y in $e'$ gives $\lambda z.y z$, which is clearly not equivalent to $\lambda y. y y$. If we want equivalent expressions to evaluate to equivalent results, we need to
change the way we perform substitution. The problem in $e$ is essentially that the $y$ starts out free, but is
\textit{captured} when we substitute it, becoming bound.  We want to avoid this, and we can do so by
renaming the bound variable to something other than $y$. (This is called $\alpha$-conversion.)

If we denote substitution of $x$ with $f$ in $e$ by $[x \mapsto f]e$,
and the free variables of $e$ by $FV(e)$, our substitution function is as follows:
\[
\begin{aligned}
& [x \mapsto e]x &= \qquad &e\\
& [x \mapsto e]y &= \qquad &y  && \text{if } y \neq x\\
& [x \mapsto e](\lambda y. f) &= \qquad &\lambda y. [x \mapsto e] f && \text{if } y \neq x \text{ and } y \notin FV(e) \\
& [x \mapsto e](e_1 e_2) &= \qquad &([x \mapsto e] e_1) ([x \mapsto e] e_2)
\end{aligned}
\]

Note that, in the case where we're substituting into a lambda expression, it looks like the substitution function
isn't total.  What happens when $x = y$, or when $y \in FV(e)$? We implicitly $\alpha$-convert in this case,
so that we can assume the necessary conditions hold.


Now that we've defined substitution precisely, we can use it to define the (small-step) evaluation relation on
lambda expressions. We'll say $e_1 \step e_2$ to mean that $e_1$ small-steps to $e_2$, i.e. that one
step of computation reduces $e_1$ to $e_2$.  These are the rules:

\begin{prooftree}
\AxiomC{$e_1 \step e_1'$}
\UnaryInfC{$e_1 e_2 \step e_1'e_2$}
\end{prooftree}

\begin{prooftree}
\AxiomC{value $v$}
\AxiomC{$e_2 \step e_2'$}
\BinaryInfC{$v \, e_2 \step v \, e_2'$}
\end{prooftree}

\begin{prooftree}
\AxiomC{value $v$}
\UnaryInfC{$(\lambda x.e_1)v \step [x \mapsto v]e_1$}
\end{prooftree}

The premise that $v$ is a value in the second and third rules guarantees a specific evaluation order---i.e.
it guarantees that the lambda calculus is deterministic.  Specifically, given an application expression,
we first evaluate the function being applied, then we evaluate the argument, then we carry out the substitution.

\subsubsection{Recursion}
The untyped lambda calculus only offers us a foundation for understanding computation because it is Turing-complete---that is, any computable function can be written as an expression in this system.
But any interesting computation involves looping or recursion, and it's not clear how we can do these
things in the lambda calculus---a system which lacks looping constructs and in which all functions are anonymous. It turns out that we can basically simulate recursion without any actual self-reference.
We just need something called a fixpoint-combinator.  I won't go into detail about how the fixpoint
combinator works.  The important point is that we don't need any extra constructs to implement recursion---a
property which won't hold for later systems.

\subsubsection{Implementation}
There are two points worth mentioning here about implementation, because they will still be relevant when
discussing more complicated systems.
First, it is more efficient (and maybe more elegant) to be lazy in our performance of substitutions.
Rather than carry them out fully right away, we can keep track of them in an \textit{environment}
and apply them as needed.  Basically, an environment is a set of deferred substitutions, and it can
be represented by a mapping from variables to values (they will always be values,
since the application rule demands that the argument be fully evaluated already).
To express the semantics of environment-based evaluation, we just have to add a rule for evaluating a variable,
and change the function application to add a variable binding to the environment.

The other point is that it is impractical to implement a programming language by simply transcribing the
small-step semantics into an interpreter. Such an implementation would have to traverse all the way down
to the bottom of an expression for each step of evaluation, resulting in many traversals in total.
There is another style of expressing operational semantics which is better suited to being transcribed
into a working implementation: big-step semantics.  While the $\step$ relation tells us what an expression
reduces to in a single computation step, the big-step $\bstep$ relation tells us what an expression
reduces to when fully evaluated.

\subsection{Simple Types}
Although this simple system is Turing-complete---we can encode natural numbers and booleans and operations on them in it---it lacks a type system. It may be obvious but I'll say it anyway: types are useful because of the fact that not all data are the same, and types allow us to express which
operations are possible on which data. In the untyped lambda calculus, even after we've
encoded numbers and booleans, it's still the case that any function can take any term as an
argument, even if the function is only ever intended to be applied to one type or the other.

A simple way to start off our type system is with integers and booleans as primitives,
each equipped with some primitive operations. In my system I have arithmetic and comparison
operations on the integers, and logical operations on the booleans (in addition to some other types
with their own operations).

But by introducing operations that are restricted to one or the other base type,
we create the possibility of expressions getting \texti{stuck} in evaluation.
That is, they might reach a state where (1) they aren't values and (2) they can't take a step. For instance the expression $true + 1$ is stuck. There's a sense in
which stuck expressions are meaningless, and we want a way to recognize statically which programs \textit{might} end up in stuck states.

\subsection{Typechecking}
This is where typechecking comes in. 


\bstctlcite{bstctl:etal, bstctl:nodash, bstctl:simpurl}
\bibliographystyle{IEEEtranS}
\bibliography{references}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
